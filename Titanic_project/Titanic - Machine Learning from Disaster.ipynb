{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import texttable as tt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection \n",
    "from sklearn import linear_model \n",
    "from sklearn import svm\n",
    "from sklearn import neural_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv', index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing unhelpful columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to preprocess the data remove unique data like the name and ticket number that may not be useful in predicting the target variable: i.e. did the passenger survive.\n",
    "\n",
    "Here we choose to remove the columns : \n",
    "- name\n",
    "- ticket number\n",
    "- Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del data.index.name # lets also remove this row with just the name on it to make things easier later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "1         0       3                            Braund, Mr. Owen Harris   \n",
       "2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "3         1       3                             Heikkinen, Miss. Laina   \n",
       "4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "5         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "1    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "2  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "3  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "5    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.drop(labels=['Name', 'Ticket', 'Cabin'], axis=1) # dropping name, ticket and Cabin columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "1         0       3    male  22.0      1      0   7.2500        S\n",
       "2         1       1  female  38.0      1      0  71.2833        C\n",
       "3         1       3  female  26.0      0      0   7.9250        S\n",
       "4         1       1  female  35.0      1      0  53.1000        S\n",
       "5         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to treat NaN values somehow as they can have break our learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "Percent dropped by removing NaNs: 20.09%\n"
     ]
    }
   ],
   "source": [
    "num_dropped_removing_Nans = len(data) - len(data.dropna()) # calculate number of entries we would drop if we dropped all entries containing NaN\n",
    "percent_dropped_removing_Nans = 100*(len(data) - len(data.dropna()))/len(data)\n",
    "\n",
    "print(num_dropped_removing_Nans) # dropping all rows with NaNs in them drops 708 examples\n",
    "print(\"Percent dropped by removing NaNs: {:.2f}%\".format(percent_dropped_removing_Nans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing entries with NaNs is not a good option as it leads to loss of almost 20% of the data, we should find another way to deal with these NaN entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at some of our NaN entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived  Pclass     Sex  Age  SibSp  Parch     Fare Embarked\n",
       "6          0       3    male  NaN      0      0   8.4583        Q\n",
       "18         1       2    male  NaN      0      0  13.0000        S\n",
       "20         1       3  female  NaN      0      0   7.2250        C\n",
       "27         0       3    male  NaN      0      0   7.2250        C\n",
       "29         1       3  female  NaN      0      0   7.8792        Q"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_temp = data[data.isnull().any(axis=1)] # get any row that has a NaN in it\n",
    "data_temp[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our options are to replace NaNs with:\n",
    "- A constant value that has meaning within the domain, such as 0, distinct from all other values.\n",
    "- A value from another randomly selected record.\n",
    "- A mean, median or mode value for the column.\n",
    "- A value estimated by another predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have tested the first 3 methods and found using the mean value to produce the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data[data.Embarked.notnull()] # remove data where embarked is null as we can't calculate a numerical value for this with the below methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we are using scikit learns imputer to guess missing values from other data, in practise the method we are using is to calculate the mean of that column and replace NaN values with the column mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "imputer = preprocessing.Imputer(strategy=\"mean\", axis=0)\n",
    "data_nans_replaced = data.copy()\n",
    "data_nans_replaced['Age'] = imputer.fit_transform(data_nans_replaced['Age'].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lets look what the NaNs were replaced with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>29.642093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Survived  Pclass     Sex        Age  SibSp  Parch     Fare Embarked\n",
       "6          0       3    male  29.642093      0      0   8.4583        Q\n",
       "18         1       2    male  29.642093      0      0  13.0000        S\n",
       "20         1       3  female  29.642093      0      0   7.2250        C\n",
       "27         0       3    male  29.642093      0      0   7.2250        C\n",
       "29         1       3  female  29.642093      0      0   7.8792        Q"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_temp = data_nans_replaced[data.isnull().any(axis=1)] # get rows of the replaced data where the rows used to contain NaNs\n",
    "data_temp[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repacing these in this way may cause some issues, but we will go forward with this method for now and see how it affects the performance of our learning algorithm later by comparing performance of the learning algorithm with some of the other methods to replace NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data_nans_replaced # replace data with data where we have replaced NaNs with mean values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check we really got rid of all the NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Percent dropped by removing NaNs: 0.00%\n"
     ]
    }
   ],
   "source": [
    "num_dropped_removing_Nans = len(data) - len(data.dropna())\n",
    "percent_dropped_removing_Nans = 100*(len(data) - len(data.dropna()))/len(data)\n",
    "\n",
    "print(num_dropped_removing_Nans) # dropping all rows with NaNs in them drops 708 examples\n",
    "print(\"Percent dropped by removing NaNs: {:.2f}%\".format(percent_dropped_removing_Nans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "1         0       3    male  22.0      1      0   7.2500        S\n",
       "2         1       1  female  38.0      1      0  71.2833        C\n",
       "3         1       3  female  26.0      0      0   7.9250        S\n",
       "4         1       1  female  35.0      1      0  53.1000        S\n",
       "5         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to encode the categorical features into many binary features. This is nessesary because of the way the algorithm interprets numbers. If we have a categorical feature that takes values 0, 1, 2, 3, 4 it assumes the higher numbers are 'better' (e.g. 4>3) even though they are arbitrary encodings, because ultimately it is calculating values/weights/parameters to be multiplied by these feature variables to give a term which enters into the linear regression. One common way to deal with this is one-hot-encoding, where a feature N takes values 0, 1, 2 for example we would generate 3 features which takes binary values 0 or 1. An example is shown below\n",
    "\n",
    "We have the original feature data:\n",
    "\n",
    "| Entry        | N          |\n",
    "| ------------ |:----------:|\n",
    "| 0            | 1          | \n",
    "| 1            | 2          |\n",
    "| 2            | 0          |\n",
    "| 3            | 1          |\n",
    "| 4            | 2          |\n",
    "| 5            | 0          |\n",
    "\n",
    "Which when encoded becomes:\n",
    "\n",
    "| Entry        | N==0       | N==1       | N==2       |\n",
    "| ------------ |:----------:|:----------:|:----------:|\n",
    "| 0            | 0          | 1          | 0          | \n",
    "| 1            | 0          | 0          | 1          | \n",
    "| 2            | 1          | 0          | 0          | \n",
    "| 3            | 0          | 1          | 0          | \n",
    "| 4            | 0          | 0          | 1          | \n",
    "| 5            | 1          | 0          | 0          | \n",
    "\n",
    "\n",
    "Here we need some insight into the data. The categorical features are:\n",
    "- pclass : the Ticket class\n",
    "- sex : the gender/sex of the passenger \n",
    "- embarked : the port where the passenger embarked from\n",
    "    - C = Cherbourg\n",
    "    - Q = Queenstown\n",
    "    - S = Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode sex with 0 or 1 and save the mapping we have used to a dictionary so we now how to transform new data we get in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      male\n",
       "2    female\n",
       "3    female\n",
       "4    female\n",
       "5      male\n",
       "Name: Sex, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Sex[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le_sex = preprocessing.LabelEncoder()\n",
    "le_sex.fit(data.Sex.unique()) # fits a value to each unique integer value of the feature variable sex\n",
    "data['Sex_numeric'] = le_sex.transform(data.Sex) # transform the data from labels to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    1\n",
       "Name: Sex_numeric, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Sex_numeric[0:5] # values are now encoded numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male', 'female', 'female', 'female', 'male'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_sex.inverse_transform(data.Sex_numeric[0:5]) # and the label encoder lets us reverse this if need be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le_Embarked = preprocessing.LabelEncoder()\n",
    "le_Embarked.fit(data.Embarked.unique()) # fits a value to each unique integer value of the feature variable sex\n",
    "data['Embarked_numeric'] = le_Embarked.transform(data.Embarked) # transform the data from labels to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_numeric</th>\n",
       "      <th>Embarked_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked  \\\n",
       "1         0       3    male  22.0      1      0   7.2500        S   \n",
       "2         1       1  female  38.0      1      0  71.2833        C   \n",
       "3         1       3  female  26.0      0      0   7.9250        S   \n",
       "4         1       1  female  35.0      1      0  53.1000        S   \n",
       "5         0       3    male  35.0      0      0   8.0500        S   \n",
       "\n",
       "   Sex_numeric  Embarked_numeric  \n",
       "1            1                 2  \n",
       "2            0                 0  \n",
       "3            0                 2  \n",
       "4            0                 2  \n",
       "5            1                 2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pclass is already numeric and takes values 1 -> 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Pclass.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_numeric</th>\n",
       "      <th>Embarked_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked  \\\n",
       "1         0       3    male  22.0      1      0   7.2500        S   \n",
       "2         1       1  female  38.0      1      0  71.2833        C   \n",
       "3         1       3  female  26.0      0      0   7.9250        S   \n",
       "4         1       1  female  35.0      1      0  53.1000        S   \n",
       "5         0       3    male  35.0      0      0   8.0500        S   \n",
       "\n",
       "   Sex_numeric  Embarked_numeric  \n",
       "1            1                 2  \n",
       "2            0                 0  \n",
       "3            0                 2  \n",
       "4            0                 2  \n",
       "5            1                 2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that Pclass and Embarked take numeric integer values we can now apply the one-hot-encoding to generate binary features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 1 of one-hot-encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc_Embarked = preprocessing.OneHotEncoder()\n",
    "encoded_column_vector = data.Embarked_numeric.values.reshape(-1,1) # gets numeric embarked data and rehsapes it to column vector\n",
    "\n",
    "Embarked_one_hot_encoded = enc_Embarked.fit_transform(encoded_column_vector).toarray() # we now apply a fit and transform step to the data simultaneous which fits the one-hot-encoder and transforms the data to one-hot-encoded data\n",
    "\n",
    "dfOneHot_Encoded = pd.DataFrame(Embarked_one_hot_encoded, \n",
    "columns = [\"Embarked_\"+le_Embarked.inverse_transform(int(i)) for i in range(Embarked_one_hot_encoded.shape[1])],\n",
    "index=data.index\n",
    ") # we now construct a dataframe out of this one-hot-encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data, dfOneHot_Encoded], axis=1)\n",
    "# we now add our one-hot-encoded Embarked features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_numeric</th>\n",
       "      <th>Embarked_numeric</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked  \\\n",
       "1         0       3    male  22.0      1      0   7.2500        S   \n",
       "2         1       1  female  38.0      1      0  71.2833        C   \n",
       "3         1       3  female  26.0      0      0   7.9250        S   \n",
       "4         1       1  female  35.0      1      0  53.1000        S   \n",
       "5         0       3    male  35.0      0      0   8.0500        S   \n",
       "\n",
       "   Sex_numeric  Embarked_numeric  Embarked_C  Embarked_Q  Embarked_S  \n",
       "1            1                 2         0.0         0.0         1.0  \n",
       "2            0                 0         1.0         0.0         0.0  \n",
       "3            0                 2         0.0         0.0         1.0  \n",
       "4            0                 2         0.0         0.0         1.0  \n",
       "5            1                 2         0.0         0.0         1.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2 of one-hot-encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Pclass_lb = preprocessing.LabelBinarizer()\n",
    "Pclass_one_hot_encoded = Pclass_lb.fit_transform(data.Pclass.values)\n",
    "\n",
    "dfOneHot_Encoded = pd.DataFrame(Pclass_one_hot_encoded, \n",
    "columns = [\"Pclass_\"+str(int(i+1)) for i in range(Pclass_one_hot_encoded.shape[1])],\n",
    "index=data.index\n",
    ") # we now construct a dataframe out of this one-hot-encoded data\n",
    "\n",
    "data = pd.concat([data, dfOneHot_Encoded], axis=1)\n",
    "# we now add our one-hot-encoded Embarked features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_numeric</th>\n",
       "      <th>Embarked_numeric</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked  \\\n",
       "1         0       3    male  22.0      1      0   7.2500        S   \n",
       "2         1       1  female  38.0      1      0  71.2833        C   \n",
       "3         1       3  female  26.0      0      0   7.9250        S   \n",
       "4         1       1  female  35.0      1      0  53.1000        S   \n",
       "5         0       3    male  35.0      0      0   8.0500        S   \n",
       "\n",
       "   Sex_numeric  Embarked_numeric  Embarked_C  Embarked_Q  Embarked_S  \\\n",
       "1            1                 2         0.0         0.0         1.0   \n",
       "2            0                 0         1.0         0.0         0.0   \n",
       "3            0                 2         0.0         0.0         1.0   \n",
       "4            0                 2         0.0         0.0         1.0   \n",
       "5            1                 2         0.0         0.0         1.0   \n",
       "\n",
       "   Pclass_1  Pclass_2  Pclass_3  \n",
       "1         0         0         1  \n",
       "2         1         0         0  \n",
       "3         0         0         1  \n",
       "4         1         0         0  \n",
       "5         0         0         1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have finished preprocessing our data we can extract our feature and target varaibles to be used to train, validate and test our learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data['Survived']\n",
    "X = data.drop(['Survived'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.drop(labels=['Sex', 'Pclass', 'Embarked', 'Embarked_numeric'], axis=1, inplace=True) # we drop the features that we have one-hot-encoded but not removed yet (we left these in to check the encoding had worked correctly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_numeric</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  SibSp  Parch     Fare  Sex_numeric  Embarked_C  Embarked_Q  \\\n",
       "1  22.0      1      0   7.2500            1         0.0         0.0   \n",
       "2  38.0      1      0  71.2833            0         1.0         0.0   \n",
       "3  26.0      0      0   7.9250            0         0.0         0.0   \n",
       "4  35.0      1      0  53.1000            0         0.0         0.0   \n",
       "5  35.0      0      0   8.0500            1         0.0         0.0   \n",
       "\n",
       "   Embarked_S  Pclass_1  Pclass_2  Pclass_3  \n",
       "1         1.0         0         0         1  \n",
       "2         0.0         1         0         0  \n",
       "3         1.0         0         0         1  \n",
       "4         1.0         1         0         0  \n",
       "5         1.0         0         0         1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Train, Validation, Test] splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets split our pre-processed data into a training set, cross validation set and test set with a 60/20/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_temp, X_test, y_temp, y_test = model_selection.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = model_selection.train_test_split(X_temp, y_temp, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split is as follows:\n",
      "-------------------------\n",
      "train: 533 \n",
      "cross-validation: 178 \n",
      "test: 178\n"
     ]
    }
   ],
   "source": [
    "print(\"Data split is as follows:\")\n",
    "print(\"-------------------------\")\n",
    "print(\"train: {} \\ncross-validation: {} \\ntest: {}\".format(X_train.shape[0], X_cv.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First lets just predict everyone dies, no learning algorithm, to see how that goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    return np.zeros(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.865168539325843"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*sum(prediction == y_test)/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This achieves an accuracy of ~57%, which doesn't seem that bad. But if we now look at the truth table of our target variable vs our prediction we can see the truth, that we are just predicting false all the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TruePositives = sum((prediction == y_test) & (y_test == 1))\n",
    "TrueNegatives = sum((prediction == y_test) & (y_test == 0))\n",
    "FalsePositives = sum((prediction != y_test) & (prediction == 1))\n",
    "FalseNegatives = sum((prediction != y_test) & (prediction == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------------+----------+\n",
      "|            |          | Real Value |          |\n",
      "+============+==========+============+==========+\n",
      "|            |          | Positive   | Negative |\n",
      "+------------+----------+------------+----------+\n",
      "| Prediction | Positive | 0          | 0        |\n",
      "+------------+----------+------------+----------+\n",
      "|            | Negative | 75         | 103      |\n",
      "+------------+----------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = tt.Texttable()\n",
    "table.add_rows([\n",
    "                [\"\", \"\", \"Real Value\", \"\"],\n",
    "                [\"\", \"\", \"Positive\", \"Negative\"],\n",
    "                [\"Prediction\", \"Positive\", TruePositives, FalsePositives],\n",
    "                [\"\", \"Negative\", FalseNegatives, TrueNegatives],\n",
    "                ])\n",
    "print(table.draw() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: nan\n",
      "Recall: 0.0\n",
      "F1score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:2: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "PredictedPositives = TruePositives + FalsePositives\n",
    "Precision = TruePositives/PredictedPositives\n",
    "\n",
    "ActualPositives = TruePositives + FalseNegatives\n",
    "Recall = TruePositives/ActualPositives\n",
    "\n",
    "print(\"Precision: {}\".format(Precision))\n",
    "\n",
    "print(\"Recall: {}\".format(Recall))\n",
    "\n",
    "F1score = 2*Precision*Recall/(Precision+Recall)\n",
    "\n",
    "print(\"F1score: {}\".format(Recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is much more obvious from this that our predicting everyone dies is a bad method to predict survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First lets attempt a logistic regression\n",
    "#### i.e. Not using any additional higher order features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now use scikit learn to fit a regularised logistic regression \n",
    "# model with each of the feature variables being linear\n",
    "# setting fit_intercept=True fits the Theta_0 term - an intercept term\n",
    "\n",
    "lr_model = linear_model.LogisticRegression(fit_intercept=True)\n",
    "\n",
    "# we now fit to the training data\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80112570356472801"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get ~80% accuracy on our training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now evaluate our performance on the cross validation data it hasn't seen. We using our cross-validation data instead of our testing data to evaluate the classifier as we are using the cross-validation performance to pick our final algorithm and we don't want to pick an algorithm that happens to work well on the testing data but doesn't generalise well to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8370786516853933"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.score(X_cv, y_cv) # this very simple logisitc regression with "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get ~80% accuracy, which is very good, lets look at our truth table, precision, recall and f1score values as well to get a better idea what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_cv = lr_model.predict(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TruePositives = sum((prediction_cv == y_cv) & (y_cv == 1))\n",
    "TrueNegatives = sum((prediction_cv == y_cv) & (y_cv == 0))\n",
    "FalsePositives = sum((prediction_cv != y_cv) & (prediction_cv == 1))\n",
    "FalseNegatives = sum((prediction_cv != y_cv) & (prediction_cv == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------------+----------+\n",
      "|            |          | Real Value |          |\n",
      "+============+==========+============+==========+\n",
      "|            |          | Positive   | Negative |\n",
      "+------------+----------+------------+----------+\n",
      "| Prediction | Positive | 58         | 11       |\n",
      "+------------+----------+------------+----------+\n",
      "|            | Negative | 18         | 91       |\n",
      "+------------+----------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = tt.Texttable()\n",
    "table.add_rows([\n",
    "                [\"\", \"\", \"Real Value\", \"\"],\n",
    "                [\"\", \"\", \"Positive\", \"Negative\"],\n",
    "                [\"Prediction\", \"Positive\", TruePositives, FalsePositives],\n",
    "                [\"\", \"Negative\", FalseNegatives, TrueNegatives],\n",
    "                ])\n",
    "print(table.draw() + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our truth table this looks much better than we got just predicting everyone dies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.841\n",
      "Recall: 0.763\n",
      "F1score: 0.800\n"
     ]
    }
   ],
   "source": [
    "PredictedPositives = TruePositives + FalsePositives\n",
    "Precision = TruePositives/PredictedPositives\n",
    "\n",
    "ActualPositives = TruePositives + FalseNegatives\n",
    "Recall = TruePositives/ActualPositives\n",
    "\n",
    "print(\"Precision: {:.3f}\".format(Precision))\n",
    "\n",
    "print(\"Recall: {:.3f}\".format(Recall))\n",
    "\n",
    "F1score = 2*Precision*Recall/(Precision+Recall)\n",
    "\n",
    "print(\"F1score: {:.3f}\".format(F1score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we now get a decent precision and recall, although recall is worse, giving us a decent F1score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve for Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the learning curve for this algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_array = np.round(np.linspace(20, X_train.shape[0], 100)).astype(int)\n",
    "train_acc_array = []\n",
    "cv_acc_array = []\n",
    "\n",
    "for m in m_array:\n",
    "    lr_model_iter = linear_model.LogisticRegression(fit_intercept=True)\n",
    "    # we now fit to the training data\n",
    "    lr_model_iter.fit(X_train.head(m), y_train.head(m)) # training on the first m training data examples\n",
    "    train_accuracy = lr_model_iter.score(X_train, y_train)\n",
    "    train_acc_array.append(train_accuracy)\n",
    "    cv_accuracy = lr_model_iter.score(X_cv, y_cv)\n",
    "    cv_acc_array.append(cv_accuracy)\n",
    "\n",
    "train_acc_array = np.array(train_acc_array)\n",
    "cv_acc_array = np.array(cv_acc_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x106efe2e8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nATQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ae13470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(m_array, 1-train_acc_array, label='train')\n",
    "ax.plot(m_array, 1-cv_acc_array, label='cross-validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel('m (size of training data)')\n",
    "ax.set_ylabel('error (1-accuracy)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on testing data: 77.53\n"
     ]
    }
   ],
   "source": [
    "accuracy = lr_model.score(X_test, y_test)\n",
    "\n",
    "print(\"accuracy on testing data: {:0.2f}\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a model accuracy of ~80% on our testing data, which the classifier has never seen before we will apply it to the actual testing data to submit to Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Test Data to Predict On for Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_kaggle_test = pd.read_csv('data/test.csv', index_col='PassengerId')\n",
    "del data_kaggle_test.index.name # lets also remove this row with just the name on it to make things easier later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass                                          Name     Sex   Age  \\\n",
       "892       3                              Kelly, Mr. James    male  34.5   \n",
       "893       3              Wilkes, Mrs. James (Ellen Needs)  female  47.0   \n",
       "894       2                     Myles, Mr. Thomas Francis    male  62.0   \n",
       "895       3                              Wirz, Mr. Albert    male  27.0   \n",
       "896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0   \n",
       "\n",
       "     SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "892      0      0   330911   7.8292   NaN        Q  \n",
       "893      1      0   363272   7.0000   NaN        S  \n",
       "894      0      0   240276   9.6875   NaN        Q  \n",
       "895      0      0   315154   8.6625   NaN        S  \n",
       "896      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_kaggle_test[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data as we did for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "data_kaggle_test = data_kaggle_test.drop(labels=['Name', 'Ticket', 'Cabin'], axis=1) # dropping name, ticket and Cabin columns\n",
    "\n",
    "data_kaggle_test['Age'] = imputer.fit_transform(data_kaggle_test['Age'].reshape(-1, 1))\n",
    "\n",
    "# ----- one-hot encoding sex ----- \n",
    "\n",
    "data_kaggle_test['Sex_numeric'] = le_sex.transform(data_kaggle_test.Sex) # transform the data from labels to numeric\n",
    "\n",
    "\n",
    "# ----- one-hot encoding Embarked ----- \n",
    "\n",
    "data_kaggle_test['Embarked_numeric'] = le_Embarked.transform(data_kaggle_test.Embarked) # transform the data from labels to numeric\n",
    "\n",
    "encoded_column_vector = data_kaggle_test.Embarked_numeric.values.reshape(-1,1) # gets numeric embarked data and rehsapes it to column vector\n",
    "\n",
    "Embarked_one_hot_encoded = enc_Embarked.transform(encoded_column_vector).toarray() # transforms the data to one-hot-encoded data\n",
    "\n",
    "dfOneHot_Encoded = pd.DataFrame(Embarked_one_hot_encoded, \n",
    "columns = [\"Embarked_\"+le_Embarked.inverse_transform(int(i)) for i in range(Embarked_one_hot_encoded.shape[1])],\n",
    "index=data_kaggle_test.index\n",
    ") # we now construct a dataframe out of this one-hot-encoded data\n",
    "\n",
    "data_kaggle_test = pd.concat([data_kaggle_test, dfOneHot_Encoded], axis=1)\n",
    "# we now add our one-hot-encoded Embarked features\n",
    "\n",
    "# ----- one-hot encoding Pclass ----- \n",
    "\n",
    "Pclass_lb = preprocessing.LabelBinarizer()\n",
    "Pclass_one_hot_encoded = Pclass_lb.fit_transform(data_kaggle_test.Pclass.values)\n",
    "\n",
    "dfOneHot_Encoded = pd.DataFrame(Pclass_one_hot_encoded, \n",
    "columns = [\"Pclass_\"+str(int(i+1)) for i in range(Pclass_one_hot_encoded.shape[1])],\n",
    "index=data_kaggle_test.index\n",
    ") # we now construct a dataframe out of this one-hot-encoded data\n",
    "\n",
    "data_kaggle_test = pd.concat([data_kaggle_test, dfOneHot_Encoded], axis=1)\n",
    "# we now add our one-hot-encoded Embarked features\n",
    "\n",
    "data_kaggle_test.drop(labels=['Sex', 'Pclass', 'Embarked', 'Embarked_numeric'], axis=1, inplace=True) # we drop the features that we have one-hot-encoded but not removed yet (we left these in to check the encoding had worked correctly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_numeric</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  SibSp  Parch     Fare  Sex_numeric  Embarked_C  Embarked_Q  \\\n",
       "892  34.5      0      0   7.8292            1         0.0         1.0   \n",
       "893  47.0      1      0   7.0000            0         0.0         0.0   \n",
       "894  62.0      0      0   9.6875            1         0.0         1.0   \n",
       "895  27.0      0      0   8.6625            1         0.0         0.0   \n",
       "896  22.0      1      1  12.2875            0         0.0         0.0   \n",
       "\n",
       "     Embarked_S  Pclass_1  Pclass_2  Pclass_3  \n",
       "892         0.0         0         0         1  \n",
       "893         1.0         0         0         1  \n",
       "894         0.0         0         1         0  \n",
       "895         1.0         0         0         1  \n",
       "896         1.0         0         0         1  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_kaggle_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inds = pd.isnull(data_kaggle_test).any(1).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_numeric</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>60.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  SibSp  Parch  Fare  Sex_numeric  Embarked_C  Embarked_Q  \\\n",
       "1044  60.5      0      0   NaN            1         0.0         0.0   \n",
       "\n",
       "      Embarked_S  Pclass_1  Pclass_2  Pclass_3  \n",
       "1044         1.0         0         0         1  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_kaggle_test[inds[0]:inds[0]+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't have a training example where the Fare was NaN so we now fit an imputer to the training data in order to impute a mean training value to use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "imputer_fare = preprocessing.Imputer(strategy=\"mean\", axis=0)\n",
    "imputer_fare.fit(data['Age'].reshape(-1, 1))\n",
    "data_kaggle_test['Fare'] = imputer_fare.transform(data_kaggle_test['Fare'].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_numeric</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>34.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>47.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>62.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>27.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>22.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>14.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>30.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>26.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>18.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>21.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>46.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>23.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.2667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>63.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>47.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61.1750</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>24.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>35.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.3500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>21.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>27.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>45.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>55.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>9.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1708</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6833</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>21.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61.3792</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>48.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>50.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>22.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61.9792</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>22.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>41.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>30.27259</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.6792</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>21.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>6.00000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>23.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>51.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.4000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>13.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>47.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>29.00000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0250</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>18.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>24.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>48.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79.2000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>22.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>31.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>30.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164.8667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>38.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>22.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>17.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>43.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>20.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>23.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>50.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>211.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7208</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>3.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.7750</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>37.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>28.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>39.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>38.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>30.27259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age  SibSp  Parch      Fare  Sex_numeric  Embarked_C  Embarked_Q  \\\n",
       "892   34.50000      0      0    7.8292            1         0.0         1.0   \n",
       "893   47.00000      1      0    7.0000            0         0.0         0.0   \n",
       "894   62.00000      0      0    9.6875            1         0.0         1.0   \n",
       "895   27.00000      0      0    8.6625            1         0.0         0.0   \n",
       "896   22.00000      1      1   12.2875            0         0.0         0.0   \n",
       "897   14.00000      0      0    9.2250            1         0.0         0.0   \n",
       "898   30.00000      0      0    7.6292            0         0.0         1.0   \n",
       "899   26.00000      1      1   29.0000            1         0.0         0.0   \n",
       "900   18.00000      0      0    7.2292            0         1.0         0.0   \n",
       "901   21.00000      2      0   24.1500            1         0.0         0.0   \n",
       "902   30.27259      0      0    7.8958            1         0.0         0.0   \n",
       "903   46.00000      0      0   26.0000            1         0.0         0.0   \n",
       "904   23.00000      1      0   82.2667            0         0.0         0.0   \n",
       "905   63.00000      1      0   26.0000            1         0.0         0.0   \n",
       "906   47.00000      1      0   61.1750            0         0.0         0.0   \n",
       "907   24.00000      1      0   27.7208            0         1.0         0.0   \n",
       "908   35.00000      0      0   12.3500            1         0.0         1.0   \n",
       "909   21.00000      0      0    7.2250            1         1.0         0.0   \n",
       "910   27.00000      1      0    7.9250            0         0.0         0.0   \n",
       "911   45.00000      0      0    7.2250            0         1.0         0.0   \n",
       "912   55.00000      1      0   59.4000            1         1.0         0.0   \n",
       "913    9.00000      0      1    3.1708            1         0.0         0.0   \n",
       "914   30.27259      0      0   31.6833            0         0.0         0.0   \n",
       "915   21.00000      0      1   61.3792            1         1.0         0.0   \n",
       "916   48.00000      1      3  262.3750            0         1.0         0.0   \n",
       "917   50.00000      1      0   14.5000            1         0.0         0.0   \n",
       "918   22.00000      0      1   61.9792            0         1.0         0.0   \n",
       "919   22.50000      0      0    7.2250            1         1.0         0.0   \n",
       "920   41.00000      0      0   30.5000            1         0.0         0.0   \n",
       "921   30.27259      2      0   21.6792            1         1.0         0.0   \n",
       "...        ...    ...    ...       ...          ...         ...         ...   \n",
       "1280  21.00000      0      0    7.7500            1         0.0         1.0   \n",
       "1281   6.00000      3      1   21.0750            1         0.0         0.0   \n",
       "1282  23.00000      0      0   93.5000            1         0.0         0.0   \n",
       "1283  51.00000      0      1   39.4000            0         0.0         0.0   \n",
       "1284  13.00000      0      2   20.2500            1         0.0         0.0   \n",
       "1285  47.00000      0      0   10.5000            1         0.0         0.0   \n",
       "1286  29.00000      3      1   22.0250            1         0.0         0.0   \n",
       "1287  18.00000      1      0   60.0000            0         0.0         0.0   \n",
       "1288  24.00000      0      0    7.2500            1         0.0         1.0   \n",
       "1289  48.00000      1      1   79.2000            0         1.0         0.0   \n",
       "1290  22.00000      0      0    7.7750            1         0.0         0.0   \n",
       "1291  31.00000      0      0    7.7333            1         0.0         1.0   \n",
       "1292  30.00000      0      0  164.8667            0         0.0         0.0   \n",
       "1293  38.00000      1      0   21.0000            1         0.0         0.0   \n",
       "1294  22.00000      0      1   59.4000            0         1.0         0.0   \n",
       "1295  17.00000      0      0   47.1000            1         0.0         0.0   \n",
       "1296  43.00000      1      0   27.7208            1         1.0         0.0   \n",
       "1297  20.00000      0      0   13.8625            1         1.0         0.0   \n",
       "1298  23.00000      1      0   10.5000            1         0.0         0.0   \n",
       "1299  50.00000      1      1  211.5000            1         1.0         0.0   \n",
       "1300  30.27259      0      0    7.7208            0         0.0         1.0   \n",
       "1301   3.00000      1      1   13.7750            0         0.0         0.0   \n",
       "1302  30.27259      0      0    7.7500            0         0.0         1.0   \n",
       "1303  37.00000      1      0   90.0000            0         0.0         1.0   \n",
       "1304  28.00000      0      0    7.7750            0         0.0         0.0   \n",
       "1305  30.27259      0      0    8.0500            1         0.0         0.0   \n",
       "1306  39.00000      0      0  108.9000            0         1.0         0.0   \n",
       "1307  38.50000      0      0    7.2500            1         0.0         0.0   \n",
       "1308  30.27259      0      0    8.0500            1         0.0         0.0   \n",
       "1309  30.27259      1      1   22.3583            1         1.0         0.0   \n",
       "\n",
       "      Embarked_S  Pclass_1  Pclass_2  Pclass_3  \n",
       "892          0.0         0         0         1  \n",
       "893          1.0         0         0         1  \n",
       "894          0.0         0         1         0  \n",
       "895          1.0         0         0         1  \n",
       "896          1.0         0         0         1  \n",
       "897          1.0         0         0         1  \n",
       "898          0.0         0         0         1  \n",
       "899          1.0         0         1         0  \n",
       "900          0.0         0         0         1  \n",
       "901          1.0         0         0         1  \n",
       "902          1.0         0         0         1  \n",
       "903          1.0         1         0         0  \n",
       "904          1.0         1         0         0  \n",
       "905          1.0         0         1         0  \n",
       "906          1.0         1         0         0  \n",
       "907          0.0         0         1         0  \n",
       "908          0.0         0         1         0  \n",
       "909          0.0         0         0         1  \n",
       "910          1.0         0         0         1  \n",
       "911          0.0         0         0         1  \n",
       "912          0.0         1         0         0  \n",
       "913          1.0         0         0         1  \n",
       "914          1.0         1         0         0  \n",
       "915          0.0         1         0         0  \n",
       "916          0.0         1         0         0  \n",
       "917          1.0         0         0         1  \n",
       "918          0.0         1         0         0  \n",
       "919          0.0         0         0         1  \n",
       "920          1.0         1         0         0  \n",
       "921          0.0         0         0         1  \n",
       "...          ...       ...       ...       ...  \n",
       "1280         0.0         0         0         1  \n",
       "1281         1.0         0         0         1  \n",
       "1282         1.0         1         0         0  \n",
       "1283         1.0         1         0         0  \n",
       "1284         1.0         0         0         1  \n",
       "1285         1.0         0         1         0  \n",
       "1286         1.0         0         0         1  \n",
       "1287         1.0         1         0         0  \n",
       "1288         0.0         0         0         1  \n",
       "1289         0.0         1         0         0  \n",
       "1290         1.0         0         0         1  \n",
       "1291         0.0         0         0         1  \n",
       "1292         1.0         1         0         0  \n",
       "1293         1.0         0         1         0  \n",
       "1294         0.0         1         0         0  \n",
       "1295         1.0         1         0         0  \n",
       "1296         0.0         1         0         0  \n",
       "1297         0.0         0         1         0  \n",
       "1298         1.0         0         1         0  \n",
       "1299         0.0         1         0         0  \n",
       "1300         0.0         0         0         1  \n",
       "1301         1.0         0         0         1  \n",
       "1302         0.0         0         0         1  \n",
       "1303         0.0         1         0         0  \n",
       "1304         1.0         0         0         1  \n",
       "1305         1.0         0         0         1  \n",
       "1306         0.0         1         0         0  \n",
       "1307         1.0         0         0         1  \n",
       "1308         1.0         0         0         1  \n",
       "1309         0.0         0         0         1  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_kaggle_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now predict on our test data and write the predictions to a CSV file to submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_kaggle_data = lr_model.predict(data_kaggle_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 892,  893,  894,  895,  896,  897,  898,  899,  900,  901,\n",
       "            ...\n",
       "            1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309],\n",
       "           dtype='int64', length=418)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_kaggle_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('prediction_submission_LR.csv', 'w') as file:\n",
    "    print('PassengerId,Survived', file=file)\n",
    "    for i, id_ in enumerate(data_kaggle_test.index):\n",
    "        print('{},{}'.format(id_, prediction_kaggle_data[i]), file=file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is quite variable, but I get scores of 75.1%-77.5% from 4 submissions with different random train/validation/test splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets now attempt to train a Support Vector Machine to predict surivival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling\n",
    "\n",
    "We will now perform feature scaling on the continous variables, namely Age, SibSp, Parch, and Fare, such that they are all around the same scale. This wasn't so important for logistic regression but IS important for SVMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:1: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  if __name__ == '__main__':\n",
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:4: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:5: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:8: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:10: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:11: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler_age = preprocessing.StandardScaler().fit(data['Age'].reshape(-1, 1))\n",
    "data['Age'] = scaler_age.transform(data['Age'].reshape(-1, 1))\n",
    "\n",
    "scaler_SibSp = preprocessing.StandardScaler().fit(data['SibSp'].reshape(-1, 1))\n",
    "data['SibSp'] = scaler_SibSp.transform(data['SibSp'].reshape(-1, 1))\n",
    "\n",
    "scaler_Parch = preprocessing.StandardScaler().fit(data['Parch'].reshape(-1, 1))\n",
    "data['Parch'] = scaler_Parch.transform(data['Parch'].reshape(-1, 1))\n",
    "\n",
    "scaler_Fare = preprocessing.StandardScaler().fit(data['Fare'].reshape(-1, 1))\n",
    "data['Fare'] = scaler_Fare.transform(data['Fare'].reshape(-1, 1))\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = model_selection.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = model_selection.train_test_split(X_temp, y_temp, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now perform our feature scaling with the fitted scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:1: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  if __name__ == '__main__':\n",
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  app.launch_new_instance()\n",
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:5: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/ajs3g11/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "data_kaggle_test['Age'] = scaler_age.transform(data_kaggle_test['Age'].reshape(-1, 1))\n",
    "\n",
    "data_kaggle_test['SibSp'] = scaler_SibSp.transform(data_kaggle_test['SibSp'].reshape(-1, 1))\n",
    "\n",
    "data_kaggle_test['Parch'] = scaler_Parch.transform(data_kaggle_test['Parch'].reshape(-1, 1))\n",
    "\n",
    "data_kaggle_test['Fare'] = scaler_Fare.transform(data_kaggle_test['Fare'].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C = 1 # start with penalty parameter equal to 1 as we don't know what value this should take yet, larger C -> lower bias, higher variance, smaller C -> higher bias, lower varaince. Since we don't have that much data a lower bias algorithm is probably best to avoid overfitting\n",
    "\n",
    "kernel = 'linear' # we'll start with a simple linear kernal to see how ths performs\n",
    "\n",
    "svm_model = svm.SVC(C=C, kernel=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7415730337078652"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.score(X_cv, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.003\n",
      "1 0.01\n",
      "2 0.02\n",
      "3 0.03\n",
      "4 0.05\n",
      "5 0.1\n",
      "6 0.3\n",
      "7 1.0\n",
      "8 3.0\n"
     ]
    }
   ],
   "source": [
    "C_array = np.array([0.003, 0.01, 0.02, 0.03, 0.05, 0.1, 0.3, 1, 3])\n",
    "train_score_array = np.zeros_like(C_array)\n",
    "validation_score_array = np.zeros_like(C_array)\n",
    "for i, C in enumerate(C_array):\n",
    "    print(i, C)\n",
    "    svm_model = svm.SVC(C=C, kernel=kernel)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    train_score_array[i] = svm_model.score(X_train, y_train)\n",
    "    validation_score_array[i] = svm_model.score(X_cv, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x107bccb38>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGwAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107b9d5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(C_array, train_score_array, label='train accuracy')\n",
    "ax.plot(C_array, validation_score_array, label='validation accuracy')\n",
    "ax.semilogx()\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C that performed best on validation data was C=0.02\n",
      "train score: 0.797, validation score: 0.764\n"
     ]
    }
   ],
   "source": [
    "index_best = np.argmax(validation_score_array)\n",
    "bestC = C_array[index_best]\n",
    "print('C that performed best on validation data was C={}'.format(bestC))\n",
    "print(\"train score: {:0.3f}, validation score: {:0.3f}\".format(train_score_array[index_best], validation_score_array[index_best]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.02, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = svm.SVC(C=bestC, kernel=kernel)\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8089887640449438"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get ~80 percent accuracy on the test data we held back from our training and validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we predict on the Kaggle data and submit to get a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_kaggle_data = svm_model.predict(data_kaggle_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('prediction_submission_SVM_Linear_Kernel.csv', 'w') as file:\n",
    "    print('PassengerId,Survived', file=file)\n",
    "    for i, id_ in enumerate(data_kaggle_test.index):\n",
    "        print('{},{}'.format(id_, prediction_kaggle_data[i]), file=file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got ~76% accuracy on Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve for Linear Kernal SVM with best C (0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, "
     ]
    }
   ],
   "source": [
    "m_array = np.round(np.linspace(20, X_train.shape[0], 20)).astype(int)\n",
    "train_acc_array = np.zeros(len(m_array))\n",
    "cv_acc_array = np.zeros(len(m_array))\n",
    "\n",
    "for i, m in enumerate(m_array):\n",
    "    print(i, end=', ')\n",
    "    svm_model_iter = svm.SVC(C=bestC, kernel=kernel)\n",
    "    # we now fit to the training data\n",
    "    svm_model_iter.fit(X_train.head(m), y_train.head(m)) # training on the first m training data examples\n",
    "    train_accuracy = svm_model_iter.score(X_train, y_train)\n",
    "    train_acc_array[i] = train_accuracy\n",
    "    cv_accuracy = svm_model_iter.score(X_cv, y_cv)\n",
    "    cv_acc_array[i] = cv_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11d3f4160>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nefLsVBmpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d3eccf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(m_array, 1-train_acc_array, label='train')\n",
    "ax.plot(m_array, 1-cv_acc_array, label='cross-validation')\n",
    "ax.legend()\n",
    "ax.set_xlabel('m (size of training data)')\n",
    "ax.set_ylabel('error (1-accuracy)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now try an SVM with a Gaussian Kernal\n",
    "\n",
    "\n",
    "### We will use the Gaussian radial-basis function (RBF kernel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = 1 # start with penalty parameter equal to 1 as we don't know what value this should take yet, larger C -> lower bias, higher variance, smaller C -> higher bias, lower varaince. Since we don't have that much data a lower bias algorithm is probably best to avoid overfitting\n",
    "\n",
    "kernel = 'rbf' # we'll use the radial basis function (Gaussian) kernal to see how ths performs\n",
    "\n",
    "gamma = 'auto' # a second hyperparameter to tune for the Guassian kernal - the width of the Gaussian function used\n",
    "\n",
    "svm_model = svm.SVC(C=C, kernel=kernel, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5842696629213483"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.score(X_cv, y_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very good performance. Since we now have 2 hyperparameters to tune we will make use of scikit learns grid_search function which allows you to provide a range of values of parameters and search over the grid for the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.01, 0.03, 0.1, 0.3, 1, 3, 10], 'gamma': [0.001, 0.01, 0.03, 0.1, 0.3, 1, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = svm.SVC(kernel=kernel)\n",
    "params = {\"C\":[0.01, 0.03, 0.1, 0.3, 1, 3, 10], \"gamma\": [0.001, 0.01, 0.03, 0.1, 0.3, 1, 3]}\n",
    "grid_search = model_selection.GridSearchCV(svm_model, params)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestC = grid_search.best_params_['C']\n",
    "best_gamma = grid_search.best_params_['gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = svm.SVC(C=bestC, kernel=kernel, gamma=best_gamma)\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.651685393258427"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.score(X_cv, y_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets try a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
